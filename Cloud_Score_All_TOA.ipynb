{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473827b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import required Google Earth Engine python packages and check if they work in python environment\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import geetools\n",
    "import geemap\n",
    "import os\n",
    "from geemap import cartoee\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the map module that allows for attaching images to an interactive map\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the river boundary from the Google Earth Engin Server\n",
    "#Call in river in from a vector file saved into Google Earth Engine\n",
    "TN_River = ee.FeatureCollection(\"projects/pjf927/assets/TN_River_Main_5000m_Divide_4\")\n",
    "#Some function require geometry values to clip features\n",
    "TN_RiverGeom = TN_River.geometry() #Some function require geometry values to clip features\n",
    "#Generate a square boundary around the river study area\n",
    "RiverBounds = TN_RiverGeom.bounds()\n",
    "#Add river boundary to the map\n",
    "Map.addLayer(RiverBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call in all landsat imagecollections that have Top of Atmosphere (TOA) pre-calcuated \n",
    "#Call in Landsat 4, Collection 2, Tier 1 TOA Reflectance \n",
    "LS4_TOA = (\n",
    "    ee.ImageCollection(\"LANDSAT/LT04/C02/T1_TOA\")\n",
    "    .filterBounds(TN_River) #Filter only swath grids that cover the TN River Boundary\n",
    "    #.filterDate(\"2013-2-11\", \"2022-12-08\") #Filter Dates of Landsat acquisitions\n",
    "    .filter(ee.Filter.eq('WRS_ROW', 36)) #Filter swath grids that completly cover the largets portion of the TN River Boundary\n",
    "    .sort('system:time_start') #Sort collection by acquisition time\n",
    ")\n",
    "\n",
    "#Call in Landsat 5, Collection 2, Tier 1 TOA Reflectance \n",
    "LS5_TOA = (\n",
    "    ee.ImageCollection(\"LANDSAT/LT05/C02/T1_TOA\")\n",
    "    .filterBounds(TN_River) #Filter only swath grids that cover the TN River Boundary\n",
    "    #.filterDate(\"2013-2-11\", \"2022-12-08\") #Filter Dates of Landsat acquisitions\n",
    "    .filter(ee.Filter.eq('WRS_ROW', 36)) #Filter swath grids that completly cover the largets portion of the TN River Boundary\n",
    "    .sort('system:time_start') #Sort collection by acquisition time\n",
    ")\n",
    "\n",
    "#Call in Landsat 7, Collection 2, Tier 1 TOA Reflectance \n",
    "LS7_TOA = (\n",
    "    ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\")\n",
    "    .filterBounds(TN_River) #Filter only swath grids that cover the TN River Boundary\n",
    "    #.filterDate(\"2013-2-11\", \"2022-12-08\") #Filter Dates of Landsat acquisitions\n",
    "    .filter(ee.Filter.eq('WRS_ROW', 36)) #Filter swath grids that completly cover the largets portion of the TN River Boundary\n",
    "    .sort('system:time_start') #Sort collection by acquisition time\n",
    ")\n",
    "\n",
    "#Call in Landsat 8, Collection 2, Tier 1 TOA Reflectance \n",
    "LS8_TOA = (\n",
    "    ee.ImageCollection(\"LANDSAT/LC08/C02/T1_TOA\")\n",
    "    .filterBounds(TN_River) #Filter only swath grids that cover the TN River Boundary\n",
    "    #.filterDate(\"2013-2-11\", \"2022-12-08\") #Filter Dates of Landsat acquisitions\n",
    "    .filter(ee.Filter.eq('WRS_ROW', 36)) #Filter swath grids that completly cover the largets portion of the TN River Boundary\n",
    "    .sort('system:time_start') #Sort collection by acquisition time\n",
    ")\n",
    "\n",
    "#Call in Landsat 9, Collection 2, Tier 1 TOA Reflectance \n",
    "LS9_TOA = (\n",
    "    ee.ImageCollection(\"LANDSAT/LC09/C02/T1_TOA\")\n",
    "    .filterBounds(TN_River) #Filter only swath grids that cover the TN River Boundary\n",
    "    #.filterDate(\"2021-10-31\", \"2022-12-08\") #Filter Dates of Landsat acquisitions\n",
    "    .filter(ee.Filter.eq('WRS_ROW', 36)) #Filter swath grids that completly cover the largets portion of the TN River Boundary\n",
    "    .sort('system:time_start') #Sort collection by acquisition time\n",
    ")\n",
    "\n",
    "#Merge all image collections to a newly created image collection called All_TOA\n",
    "All_TOA = LS4_TOA.merge(LS5_TOA.merge(LS7_TOA.merge(LS8_TOA.merge(LS9_TOA))))\n",
    "\n",
    "#Get a count of all images in the Landsat Top of Atmosphere Collection\n",
    "pre_count = All_TOA.size().getInfo()\n",
    "print(\"Images: \", pre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d265e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fucntion that calcualtes the percent of clounds that cover the river geometry\n",
    "def func_rdd(image):\n",
    "  cloud = ee.Algorithms.Landsat.simpleCloudScore(image).select('cloud')\n",
    "  cloudiness = cloud.reduceRegion(\n",
    "    reducer = ee.Reducer.mean(),\n",
    "    geometry = TN_RiverGeom,\n",
    "    scale = 30,\n",
    "  )\n",
    "  return image.set(cloudiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48091e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply each equation to the clipped pixels in each sensor specific image collection that are in the TN River boundary\n",
    "LS4_Cloudy = LS4_TOA.map(func_rdd)\n",
    "LS5_Cloudy = LS5_TOA.map(func_rdd)\n",
    "LS7_Cloudy = LS7_TOA.map(func_rdd)\n",
    "LS8_Cloudy = LS8_TOA.map(func_rdd)\n",
    "LS9_Cloudy = LS9_TOA.map(func_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out images that are less than 1 percent of clounds in the TN River boundary for each image collection\n",
    "LS4_Filt = LS4_Cloudy.filter(ee.Filter.lt('cloud', 1))\n",
    "\n",
    "LS5_Filt = LS5_Cloudy.filter(ee.Filter.lt('cloud', 1))\n",
    "\n",
    "LS7_Filt = LS7_Cloudy.filter(ee.Filter.lt('cloud', 1))\n",
    "\n",
    "LS8_Filt = LS8_Cloudy.filter(ee.Filter.lt('cloud', 1))\n",
    "\n",
    "LS9_Filt = LS9_Cloudy.filter(ee.Filter.lt('cloud', 1))\n",
    "\n",
    "#Merge all image collections to a newly created image collection called All_Filt\n",
    "All_Filt = LS4_Filt.merge(LS5_Filt.merge(LS7_Filt.merge(LS8_Filt.merge(LS9_Filt)))).sort('system:time_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7208e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a count of all images in the Landsat Top of Atmosphere Collection that weren't filtered\n",
    "print(\"Images Before Cloud Filter: \", pre_count)\n",
    "\n",
    "#Get a count of all images in the Landsat Top of Atmosphere Collection that were filtered\n",
    "filt_count = All_Filt.size().getInfo()\n",
    "print(\"Images After Cloud Filter: \", filt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that creates a new dictionary in the image collection called 'Date' and converts the 'system:time_start' list to a \"YYYY-MM-dd\" format\n",
    "All_Filt_Dates = All_Filt.map(\n",
    "    lambda img: img.set({\"DATE\": ee.Date(img.get(\"system:time_start\")).format(\"YYYY-MM-dd\")})\n",
    ")\n",
    "\n",
    "#Create a list of dates and print them out\n",
    "Dates = All_Filt_Dates.aggregate_array(\"DATE\").getInfo()\n",
    "print(\"Dates in Imagecollection: \", dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of sensor acquisitions and print them out\n",
    "Sensor = All_Filt.aggregate_array(\"SPACECRAFT_ID\").getInfo()\n",
    "print(Sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ed876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of swath row acquisitions and print them out\n",
    "Swath = All_Filt.aggregate_array(\"WRS_ROW\").getInfo()\n",
    "print(Swath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of scloud percentages and print them out\n",
    "CLD_Percent = All_Filt.aggregate_array(\"cloud\").getInfo()\n",
    "print(CLD_Percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save each list as a pandas dataframe\n",
    "Acquisition_Data = pd.DataFrame(list(zip(Dates, Sensor, Swath, CLD_Percent)), \n",
    "                                columns=['Date','Sensor', 'Swath_Row', 'Cloud_Percent'])\n",
    "\n",
    "print(Acquisition_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe as a csv to a folder directory\n",
    "pd.DataFrame(Acquisition_Data).to_csv(r\"D:\\School\\Adv_Data_Analytics\\Project\\csv\\Cloud_Score_Acquisition_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
